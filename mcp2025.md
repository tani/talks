---
marp: true
theme: default
---

# MCPの紹介

Masaya Taniguchi

---

## MCPってなに

> MCPはLLMsに文脈をどう渡すかを標準化した開かれたプロトコルです。
> https://modelcontextprotocol.io/


---

## MCPサーバーの普及状況

有名サービス・ソフトウェアが続々と公式MCPサーバーを公開
- [MCP Server for Windows](https://blogs.windows.com/windowsexperience/2025/05/19/securing-the-model-context-protocol-building-a-safer-agentic-future-on-windows/)
- [GitHub's official MCP Server ](https://github.com/github/github-mcp-server)
- [Notion MCP Server](https://github.com/makenotion/notion-mcp-server)
- [AWS MCP Servers](https://github.com/awslabs/mcp)

→ MCPサーバーをつくるだけで、LLMsがエージェント的に使ってくれる!

---

## LLMプロバイダの対応状況

- OpenAIはSDK経由で対応
  https://openai.github.io/openai-agents-python/ja/mcp/
- Anthropic は SDK/ Desktopアプリで対応
- Google は発表なし

## クライアントの対応状況

- [LangChain MCP Adapters](https://github.com/langchain-ai/langchain-mcp-adapters)
- [GitHub Copilot](https://docs.github.com/en/copilot/customizing-copilot/extending-copilot-chat-with-mcp)

---

## Tips: LLMs.txt

言語モデルにウェブサービスの内容をすべて読ませるための
プロトコルが Answer.ai (ModernBERTを開発したところ) いによって提案されている。ウェブサービスの内容をすべて txtファイルに書き出したものをサービス直下に置きましょうという提案。

mcp の公式ページにも llms.txt がある。これを NotebookLMに渡すと便利。

https://modelcontextprotocol.io/llms.txt
https://modelcontextprotocol.io/llms-full.txt

---

## MCPプロトコルの概要

MCPサーバーは、主に以下の3種類の機能を提供できます。

- *プロンプト (Prompts)*: AIモデルとの対話をガイドするための事前に定義されたテンプレートや指示を提供します。これにより、ユーザーはより簡単にAIモデルと効果的にコミュニケーションをとることができます。
- *リソース (Resources)*: AIモデルに追加のコンテキスト（文脈情報）を提供するための構造化されたデータやコンテンツへのアクセスを可能にします。例えば、ファイルシステム、データベース、API連携などがこれに該当します。
- *ツール (Tools)*: AIモデルが特定の操作を実行したり、情報を取得したりするための実行可能な機能を提供します。これにより、AIモデルは単に情報を処理するだけでなく、具体的なタスクを実行できるようになります。

<p align="center">
    <strong>使い方を知る → ターゲットを読み込む → ターゲットへ書き込む</strong>
</p>

---

## Python でつくる MCP サーバー

- ライブラリはここに公開されている。
 https://github.com/modelcontextprotocol/python-sdk
- PyPIには `mcp` という名前で登録されてます。

---

## 

- ライブラリはここに公開されている。
 https://github.com/modelcontextprotocol/python-sdk
- PyPIには `mcp` という名前で登録されてます。
